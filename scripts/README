This dir contains various shell scripts used for the OSG portal:



### gemcSubmitCron.sh

- run by user "gemc" on on scosg20.jlab.org
- 2 minute crontab:

*/2  *  *  *  * flock -n $HOME/.submit.lock $HOME/gemcSubmitCron.sh >& $HOME/submitCron.log   >/dev/null 2>&1

- runs python src/Submit_UserSubmission.py : browse DB for non submitted jobs, and submit to OSG


### osgQuery.sh

- run by user "gemc" on scosg20.jlab.org
- 5 minutes crontab:

*/5 * * * * flock -n $HOME/.jlog.lock $HOME/osgQuery.sh  > $HOME/logs/`date +\%d\%m\%y_\%H\%M\%S`".log" 2>&1

- this script produces 2 outputs inside web_interface/data:
	a. gemcRunning.log that contains the output of condor
	b. osgLog.json, a JSON file containing the breakdown of usage per user, used by priority cron



 ### priorityCron.sh

- run by user "gemc" on on scosg16.jlab.org
- 2 minute crontab: */2 * * * * ~/priorityCron.sh >& ~/priorityCron.log
- runs /home/gemc/software/Submit/utils/update_priority.py with web_interface/data/osgLog.json as input
- produces 3 lines piped to condor_prior to increase priority according to number of jobs


### bkgrd_to_json

- run to produce the json file needed by the web_interface to load the configuration. Output in web_interface/data/xrootd.json


### volatileQuery.sh

- run by user "ungaro" on a CUE machine, NOT scosg16.jlab.org (so it's not to slow it down)
- 4 hours crontab: 44 */4 * * * ~/volatileQuery.sh
- this script produces 2 outputs inside  web_interface/data:
	a. volatile.log: a summary of disk usage (output of du)
	b. disk.json: a JSON file containiing the breakdown of disk usage per user
